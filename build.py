import os
import json
import argparse
import re
import sys
from pathlib import Path

def parse_args():
    parser = argparse.ArgumentParser(description="Build Image Editing Testset")
    parser.add_argument("--mode", type=str, required=True, choices=['drone', 'egovid', 'walk'], help="Dataset mode")
    parser.add_argument("--source_json", type=str, required=True, help="Path to original metadata JSON")
    parser.add_argument("--image_dir", type=str, required=True, help="Directory for verification (Egovid) or Ignored")
    parser.add_argument("--output_path", type=str, required=True, help="Path to save the output testset JSON")
    parser.add_argument("--filter_ids", type=str, default=None, help="Optional: Comma separated IDs to filter")
    return parser.parse_args()

def load_source_data(json_path):
    print(f"ğŸ“– Loading source data from {json_path}...")
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œè½¬ä¸º dict mapï¼›å¦‚æœæ˜¯ dictï¼Œç›´æ¥ä½¿ç”¨
        if isinstance(data, list):
            return {item['id']: item for item in data}
        else:
            return data
    except Exception as e:
        print(f"âŒ Error loading source JSON: {e}")
        sys.exit(1)

def main():
    args = parse_args()
    source_map = load_source_data(args.source_json)
    
    testset = []
    target_ids = set(args.filter_ids.split(',')) if args.filter_ids else None
    
    print(f"ğŸ“‚ Current Working Directory: {os.getcwd()}")
    
    # ==========================================
    # æ¨¡å¼ A: Drone / Walk (åŸæœ‰é€»è¾‘ï¼šæ­£åˆ™åŒ¹é… key)
    # ==========================================
    if args.mode in ['drone', 'walk']:
        print(f"ğŸš€ Mode [{args.mode}]: Iterating JSON with Regex Matching")
        
        total_keys_found = 0
        files_missing = 0
        
        for original_id, item in source_map.items():
            if target_ids and original_id not in target_ids:
                continue

            json_path = item.get('last_frame_path', '')
            if not json_path: continue

            pattern = re.compile(r'^SC\d+_MOD_\d+$')

            for key, prompt_text in item.items():
                if pattern.match(key):
                    total_keys_found += 1
                    full_path = os.path.join(json_path, f"{key}.jpg")
                    
                    if os.path.exists(full_path):
                        testset.append({
                            "test_id": f"{original_id}_{key}",
                            "original_id": original_id,
                            "prompt": prompt_text,
                            "prompt_key": key,
                            "last_frame_path": full_path,
                            "first_frame_path": item.get('first_frame_path'),
                            "mode": args.mode
                        })
                    else:
                        files_missing += 1
                        if files_missing <= 3:
                            print(f"âŒ [Missing] {full_path}")

        print(f"   - Total keys processed: {total_keys_found}")
        print(f"   - Files missing: {files_missing}")

    # ==========================================
    # æ¨¡å¼ B: Egovid (ä¿®æ”¹åï¼šç›´æ¥è¯»å– JSON è·¯å¾„)
    # ==========================================
    elif args.mode == 'egovid':
        print(f"ğŸš€ Mode [{args.mode}]: Iterating JSON and verifying last_frame_path")
        
        files_missing = 0
        
        for original_id, item in source_map.items():
            if target_ids and original_id not in target_ids:
                continue
            
            # 1. è·å–è·¯å¾„
            # æ ¹æ®æä¾›çš„ metadataï¼Œè·¯å¾„ç›´æ¥å°±åœ¨ last_frame_path å­—æ®µé‡Œ
            relative_path = item.get('last_frame_path')
            
            if not relative_path:
                continue
                
            # 2. éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            # å‡è®¾ metadata ä¸­çš„è·¯å¾„æ˜¯ç›¸å¯¹äºè¿è¡Œç›®å½•çš„ (å¦‚ results/exp_unified/...)
            if os.path.exists(relative_path):
                # 3. è·å– Prompt (ä¼˜å…ˆå– lf_prompt_v4_minimal)
                prompt = item.get('lf_prompt_v4_minimal')
                if not prompt:
                    # å¦‚æœ minimal æ²¡æœ‰ï¼Œå°è¯• fallback åˆ° instruction æˆ–å…¶ä»–å­—æ®µ
                    prompt = item.get('instruction', '')
                
                testset.append({
                    "test_id": original_id, # Egovid ID æœ¬èº«å°±æ˜¯å”¯ä¸€çš„
                    "original_id": original_id,
                    "prompt": prompt,
                    "prompt_key": "lf_prompt_v4_minimal",
                    "last_frame_path": relative_path,
                    "first_frame_path": item.get('first_frame_path'),
                    "mode": args.mode
                })
            else:
                files_missing += 1
                if files_missing <= 3:
                    print(f"âŒ [Missing] JSON path not found on disk: {relative_path}")
        
        print(f"   - Files missing: {files_missing}")

    # ==========================================
    # è¾“å‡º JSON æ–‡ä»¶ (Dataset Output)
    # ==========================================
    os.makedirs(os.path.dirname(args.output_path), exist_ok=True)
    with open(args.output_path, 'w', encoding='utf-8') as f:
        json.dump(testset, f, indent=4, ensure_ascii=False)
        
    print(f"âœ… JSON Build Complete! Valid items: {len(testset)}")
    print(f"ğŸ’¾ Saved Dataset to: {args.output_path}")

    # ==========================================
    # è¾“å‡º Log æ–‡ä»¶ (JSON æ ¼å¼)
    # ==========================================
    log_dir = os.path.join("results", "exp_unified", "logs")
    os.makedirs(log_dir, exist_ok=True)
    
    log_filename = f"{args.mode}.json"
    log_path = os.path.join(log_dir, log_filename)

    print(f"ğŸ“ Generating Log file: {log_path} ...")
    
    log_data = {
        "mode": args.mode,
        "total_count": len(testset),
        "items": []
    }

    for item in testset:
        log_data["items"].append({
            "test_id": item.get('test_id'),
            "last_frame_path": item.get('last_frame_path')
        })
    
    try:
        with open(log_path, 'w', encoding='utf-8') as f_log:
            json.dump(log_data, f_log, indent=4, ensure_ascii=False)
        print(f"âœ… Log Saved to: {log_path}")
    except Exception as e:
        print(f"âŒ Error writing log file: {e}")

if __name__ == "__main__":
    main()